{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a20ece5-2a04-42c2-86f4-b3a6129fc6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "data_path = \"./gg2015.json\"\n",
    "df = pd.read_json(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Analyze common phrase occurences\n",
    "'''\n",
    "Input: A list of strings after parsing\n",
    "Output: The most common grams containing 'best'\n",
    "Remarks:\n",
    "    1. Longest award phrase is 12 words\n",
    "'''\n",
    "def common_phrases(keywords):\n",
    "    bigrams = []\n",
    "    trigrams = []\n",
    "    quadgrams = []\n",
    "    multigrams = []\n",
    "    megagrams = []\n",
    "    for item in keywords:\n",
    "        clean_string = re.sub('[^A-Za-z0-9]+', ' ', item)\n",
    "        tokens = nltk.word_tokenize(clean_string)\n",
    "        grams2 = ngrams(tokens, 2)\n",
    "        grams3 = ngrams(tokens, 3)\n",
    "        grams4 = ngrams(tokens, 4)\n",
    "        grams9 = ngrams(tokens, 9)\n",
    "        grams12 = ngrams(tokens, 12)\n",
    "        for gram in grams2:\n",
    "            bigrams.append(gram)\n",
    "        for gram in grams3:\n",
    "            trigrams.append(gram)\n",
    "        for gram in grams4:\n",
    "            quadgrams.append(gram)\n",
    "        for gram in grams9:\n",
    "            multigrams.append(gram)\n",
    "        for gram in grams12:\n",
    "            megagrams.append(gram)\n",
    "\n",
    "    common2 = Counter(bigrams).most_common()\n",
    "    common3 = Counter(trigrams).most_common()\n",
    "    common4 = Counter(quadgrams).most_common()\n",
    "    common9 = Counter(multigrams).most_common()\n",
    "    common12 = Counter(megagrams).most_common()\n",
    "\n",
    "    common2 = filter(lambda x: x[0][0] == \"best\", common2)\n",
    "    common3 = filter(lambda x: x[0][0] == \"best\", common3)\n",
    "    common4 = filter(lambda x: x[0][0] == \"best\", common4)\n",
    "    common9 = filter(lambda x: x[0][0] == \"best\", common9)\n",
    "    common12 = filter(lambda x: x[0][0] == \"best\", common12)\n",
    "\n",
    "    common2 = list(common2)\n",
    "    common3 = list(common3)\n",
    "    common4 = list(common4)\n",
    "    common9 = list(common9)\n",
    "    common12 = list(common12)\n",
    "\n",
    "    combined = common2 + common3 + common4 + common9 + common12\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Input: List of strings\n",
    "Output: Strings with its frequency\n",
    "Remarks:\n",
    "    1. Can also count common strings in strings for strategy2\n",
    "'''\n",
    "def most_common_beststring(strings):\n",
    "    best_string = filter(lambda x: \"best\" in x, strings)\n",
    "    best_string = list(best_string)\n",
    "    return Counter(best_string).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Strategy 1 scan after the word won:\n",
    "df2 = df[df['text'].str.contains(\" won \") | df['text'].str.contains(\" Won \")]\n",
    "tweets = df2['text'].tolist()\n",
    "keywords = []\n",
    "#regexp = re.compile(r'[!?.;#]+(?=$|\\s)')\n",
    "regexp = re.compile(r'[!?.;#,@:]')\n",
    "\n",
    "stop_words = ['at','and','on','because','but','tonight','before','lol','since','i','I']\n",
    "\n",
    "#Parse Keywords. All phrase after 'won best' will be captured.\n",
    "for tweet in tweets:\n",
    "    words = tweet.lower().split()\n",
    "    index_won = words.index(\"won\")\n",
    "    if words[index_won + 1] == \"best\":\n",
    "        keyword = \"best \"\n",
    "        curr_index = index_won + 2\n",
    "        while curr_index != len(words):\n",
    "            if regexp.search(words[curr_index]) or words[curr_index] in stop_words:\n",
    "                #keyword += words[curr_index]\n",
    "                keyword = keyword.strip()\n",
    "                break\n",
    "            keyword += words[curr_index] + \" \"\n",
    "            curr_index += 1\n",
    "        keywords.append(keyword)\n",
    "\n",
    "strategy1 = common_phrases(keywords)\n",
    "#print(strategy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Strategy 2 scan before the word won:\n",
    "df3 = df[df['text'].str.contains(\" goes to \")]\n",
    "tweets = df3['text'].tolist()\n",
    "keywords2 = []\n",
    "#Parse Backwards, stop at the word best\n",
    "for tweet in tweets:\n",
    "    words = nltk.word_tokenize(tweet.lower())\n",
    "    index = words.index(\"to\")\n",
    "    if words[index - 1] == \"goes\":\n",
    "        keyword = \"\"\n",
    "        curr_index = index - 2\n",
    "        while curr_index >= 0:\n",
    "            if curr_index == 0 or words[curr_index] == \"best\":\n",
    "                keyword = words[curr_index] + keyword\n",
    "                break\n",
    "            keyword = \" \" + words[curr_index] + keyword\n",
    "            curr_index -= 1\n",
    "        keywords2.append(keyword)\n",
    "\n",
    "#print(keywords2)\n",
    "strategy2 = common_phrases(keywords2)\n",
    "#print(strategy2)\n",
    "\n",
    "#most_common_beststring(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "common_strings = most_common_beststring(keywords2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Input: gram sets\n",
    "Output: phrases with frequency\n",
    "'''\n",
    "def accumulate_votes(grams1, grams2, common_strings):\n",
    "    awards = {}\n",
    "    '''\n",
    "    for gram in grams1:\n",
    "        untokenize = ' '.join(gram[0])\n",
    "        awards[untokenize] = len(gram[0]) * gram[1]\n",
    "    for gram in grams2:\n",
    "        untokenize = ' '.join(gram[0])\n",
    "        if untokenize in awards:\n",
    "            awards[untokenize] = awards[untokenize] * 2.5\n",
    "        else:\n",
    "            awards[untokenize] = len(gram[0]) * gram[1]\n",
    "    '''\n",
    "    for string in common_strings:\n",
    "        first_two = ' '.join(nltk.word_tokenize(string[0])[:2])\n",
    "        if string[0] in awards:\n",
    "            awards[string[0]] = awards[string[0]] * 2.5\n",
    "        elif first_two in awards:\n",
    "            awards[string[0]] = awards[first_two] * string[1]\n",
    "        else:\n",
    "            awards[string[0]] = len(string[0]) * string[1]\n",
    "    return sorted(awards.items(), key = lambda x: x[1], reverse = True)\n",
    "votes = accumulate_votes(strategy1, strategy2, common_strings)\n",
    "#Need a way to combine similar categories\n",
    "print(len(votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "957\n"
     ]
    }
   ],
   "source": [
    "collocation_words = {\n",
    "    #\"tv\":\"television\",\n",
    "    \"pic\":\"picture\",\n",
    "    \"for\":\"-\",\n",
    "    \"in\":\"-\",\n",
    "    'or':'/',\n",
    "    'of':'-'\n",
    "}\n",
    "\n",
    "skip_words = ['a']\n",
    "\n",
    "paraphrase = [',','@','(',')','#']\n",
    "\n",
    "# Find a good format for award names.\n",
    "def gram_cleaning(grams):\n",
    "    new_grams = []\n",
    "    for gram in grams:\n",
    "        word_list = []\n",
    "        for word in gram[0]:\n",
    "            if word in collocation_words:\n",
    "                word = collocation_words[word]\n",
    "            if word in skip_words:\n",
    "                break\n",
    "            if word not in paraphrase:\n",
    "                word_list.append(word)\n",
    "        word_tuple = tuple(word_list)\n",
    "        gram_tuple = (word_tuple,gram[1])\n",
    "        new_grams.append(gram_tuple)\n",
    "    return new_grams\n",
    "\n",
    "# Separate 'A/B' type of words into 'A / B' to add more information to resolute.\n",
    "def sticky_word_string(phrase):\n",
    "    phrase_list = nltk.word_tokenize(phrase)\n",
    "    token_list = []\n",
    "    for word in phrase_list:\n",
    "        flag = 0\n",
    "        for i,character in enumerate(word):\n",
    "            if character == '/' and i != 0:\n",
    "                token_list.append(word[0:i])\n",
    "                token_list.append(word[i])\n",
    "                flag = i\n",
    "                if i != len(word)-1:\n",
    "                    token_list.append(word[i+1:len(word)])\n",
    "                break\n",
    "        if flag == 0 and word not in skip_words:\n",
    "            token_list.append(word)\n",
    "    clean_string = ' '.join(token_list)\n",
    "    return clean_string\n",
    "\n",
    "# Replacing some collocation words.\n",
    "def string_cleaning(grams):\n",
    "    new_grams = []\n",
    "    for gram in grams:\n",
    "        word_list = []\n",
    "        clean_gram = sticky_word_string(gram[0])\n",
    "        temp_list = nltk.word_tokenize(clean_gram)\n",
    "        for word in temp_list:\n",
    "            if word in collocation_words:\n",
    "                word = collocation_words[word]\n",
    "            if word not in paraphrase:\n",
    "                word = word.strip()\n",
    "                word_list.append(word)\n",
    "        phrase = ' '.join(word_list)\n",
    "        gram_tuple = (phrase,gram[1])\n",
    "        new_grams.append(gram_tuple)\n",
    "    return new_grams\n",
    "\n",
    "#for vote in votes:\n",
    "#print(strategy1)\n",
    "new1 = gram_cleaning(strategy1)\n",
    "new2 = gram_cleaning(strategy2)\n",
    "new3 = string_cleaning(common_strings)\n",
    "votes = accumulate_votes(new1, new2, new3)\n",
    "#Need a way to combine similar categories\n",
    "print(len(votes))\n",
    "#votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Ignore paraphrases and merge the similar results. Get new votes.\n",
    "words_pattern = '[a-zA-Z]+'\n",
    "resolution_list = []\n",
    "awards_dict = {}\n",
    "for i,vote in enumerate(votes):\n",
    "    words = re.findall(words_pattern, vote[0], flags=re.IGNORECASE)\n",
    "    words = ' '.join(words)\n",
    "    if words in awards_dict:\n",
    "        awards_dict[words].append(i)\n",
    "    else:\n",
    "        awards_dict[words] = [i]\n",
    "#pprint(awards_dict)\n",
    "\n",
    "new_list = []\n",
    "for key, val in awards_dict.items():\n",
    "    if len(val) == 1:\n",
    "        new_list.append(list(votes[val[0]]))\n",
    "    else:\n",
    "        sum = 0\n",
    "        for i in val:\n",
    "            sum+=votes[i][1]\n",
    "        new_list.append([votes[val[0]][0],sum])\n",
    "#new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TF-IDF computation. Get a weighted word vector representation.\n",
    "'''\n",
    "pd. set_option('display.max_columns', None)\n",
    "pd. set_option('display.max_rows', None)\n",
    "\n",
    "corpus = []\n",
    "for item in new_list:\n",
    "    corpus.append(item[0][1:])\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "tfidf = pd.DataFrame(denselist, columns=feature_names)\n",
    "\n",
    "# Add more importance to some key words (can get from user inputs) which most distinguish different award names.\n",
    "keyword_list = ['actress','supporting','actor','director','drama','musical','television','comedy','tv']\n",
    "for keyword in keyword_list:\n",
    "    tfidf[keyword] = tfidf[keyword]*2\n",
    "#tfidf.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The merging result:\n"
     ]
    }
   ],
   "source": [
    "# Compute pair similarity between each word vectors.\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Larger threshold means merge more strictly.\n",
    "threshold = 0.9\n",
    "final_list = []\n",
    "cs = cosine_similarity(tfidf,tfidf)\n",
    "#ans = pairwise_distances(tfidf,tfidf,'chebyshev')\n",
    "index_list = []\n",
    "for v,score_row in enumerate(cs):\n",
    "    similarity = []\n",
    "    merge_index = [v]\n",
    "    for i, score in enumerate(score_row):\n",
    "        if score > threshold and v!=i:\n",
    "            similarity.append([new_list[v],score,new_list[i],v,i])\n",
    "            merge_index.append(i)\n",
    "    final_list.append(similarity)\n",
    "    index_list.append(merge_index)\n",
    "print('The merging result:')\n",
    "#pprint(final_list)\n",
    "#index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Similarity Graph merging\n",
    "Find the similar clusters by recursively merging the similar sentences.\n",
    "Use the highest score sentence as its cluster name.\n",
    "'''\n",
    "\n",
    "\n",
    "def merge_index(curr_index,original_list,curr_cluster):\n",
    "    for index in original_list[curr_index]:\n",
    "        if index not in curr_cluster:\n",
    "            curr_cluster.append(index)\n",
    "            merge_index(index,original_list,curr_cluster)\n",
    "    return curr_cluster\n",
    "\n",
    "cluster_list = []\n",
    "access = []\n",
    "for v,il in enumerate(index_list):\n",
    "    if v not in access:\n",
    "        cl = merge_index(v,index_list,[])\n",
    "        for i in cl:\n",
    "            access.append(i)\n",
    "        cluster_list.append(cl)\n",
    "\n",
    "final_result = []\n",
    "for cluster in cluster_list:\n",
    "    sum_s = 0\n",
    "    for item in cluster:\n",
    "        sum_s += new_list[item][1]\n",
    "    item_list = [new_list[cluster[0]][0],sum_s]\n",
    "    final_result.append(item_list)\n",
    "\n",
    "\n",
    "def sort_score(e):\n",
    "    return e[1]\n",
    "final_result.sort(reverse=True,key=sort_score)\n",
    "\n",
    "#pprint(final_result)\n",
    "print(len(final_result))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Currently use 40 as its possible awards number. Can let user input awards number and double it.\n",
    "final_awards_name = final_result[:40]\n",
    "#pprint(final_awards_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "awards_token_dict = {}\n",
    "removable_tokens = {'mini','-','/','feature'}\n",
    "for i, awards_name in enumerate(final_awards_name):\n",
    "    #clean_string = re.sub('[^A-Za-z0-9]+', ' ', awards_name[0])\n",
    "    clean_string = awards_name[0]\n",
    "    tokens = nltk.word_tokenize(clean_string)\n",
    "    for rt in removable_tokens:\n",
    "        if rt in tokens:\n",
    "            tokens.remove(rt)\n",
    "    awards_token_dict[awards_name[0]] = [tokens]\n",
    "    #print(tokens)\n",
    "    if ' / ' in awards_name[0]:\n",
    "        dirty_tokens = nltk.word_tokenize(awards_name[0])\n",
    "        i = dirty_tokens.index('/')\n",
    "        stickytoken = dirty_tokens[i-1] + '/' + dirty_tokens[i+1]\n",
    "        tokens1 = tokens[:]\n",
    "        #tokens1.remove('/')\n",
    "        s1 = dirty_tokens[i-1]\n",
    "        s2 = dirty_tokens[i+1]\n",
    "        if s1 in tokens1:\n",
    "            tokens1.remove(s1)\n",
    "        if s2 in tokens1:\n",
    "            tokens1.remove(s2)\n",
    "        tokens1.append(stickytoken)\n",
    "        awards_token_dict[awards_name[0]].append(tokens1)\n",
    "        \n",
    "\n",
    "#pprint(awards_token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_people_names(store,text_list,awards_name,awards_token,tweet_store):\n",
    "    for tid, tweet in enumerate(text_list):\n",
    "        for award_token in awards_token:\n",
    "            if all(token in tweet.lower() for token in award_token):\n",
    "                if awards_name in store:\n",
    "                    store[awards_name].append(tweet)\n",
    "                    tweet_store[awards_name].append([tid,tweet])\n",
    "                else:\n",
    "                    store[awards_name] = [tweet]\n",
    "                    tweet_store[awards_name]=[[tid,tweet]]\n",
    "        if  awards_name in store.keys() and len(store[awards_name]) > 500:\n",
    "            break\n",
    "    return [store, tweet_store]\n",
    "\n",
    "def construct_regex(num):\n",
    "    final = ''\n",
    "    for i in range(num):\n",
    "        substr = '[A-Z][a-z]* ?'\n",
    "        final += substr\n",
    "    final1 = '\"'+final+'\"'\n",
    "    return final1\n",
    "\n",
    "def extract_movie_song(store,text_list,awards_name,awards_token,num,tweet_store):\n",
    "    occupation_words = [\"actor\",\"director\",\"actress\",\"singer\",\"scientist\"]\n",
    "    for tid, tweet in enumerate(text_list):\n",
    "        for award_token in awards_token:\n",
    "            if all(token in tweet.lower() for token in award_token) and not any(occupation in tweet.lower() for occupation in occupation_words):\n",
    "                for i in range(1,num):\n",
    "                    regexp = construct_regex(i)\n",
    "                    x = re.findall(regexp,tweet)\n",
    "                    if len(x) != 0:\n",
    "                        if awards_name in store:\n",
    "                            store[awards_name]+=x\n",
    "                        else:\n",
    "                            store[awards_name] = x\n",
    "                if awards_name in tweet_store:\n",
    "                    tweet_store[awards_name].append([tid,tweet])\n",
    "                else:\n",
    "                    tweet_store[awards_name] = [[tid,tweet]]\n",
    "        if  awards_name in store.keys() and len(store[awards_name]) > 1000:\n",
    "            break\n",
    "    return [store, tweet_store]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "store = dict()\n",
    "tweet_store = dict()\n",
    "df = pd.read_json(data_path)['text']\n",
    "occupation_words = [\"actor\",\"director\",\"actress\",\"singer\",\"scientist\"]\n",
    "for awards_name, awards_token in awards_token_dict.items():\n",
    "    if any(occupation in awards_name for occupation in occupation_words):\n",
    "        [store, tweet_store] = extract_people_names(store,df,awards_name,awards_token,tweet_store)\n",
    "        # Award for movie/songs\n",
    "    else:\n",
    "        [store, tweet_store] = extract_movie_song(store,df,awards_name,awards_token,5,tweet_store)\n",
    "\n",
    "\n",
    "    #print(store)\n",
    "#pprint(store)\n",
    "#pprint(tweet_store)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df.iloc[0:10000]\n",
    "df4 = df5[df5.str.contains(\" hosts \", case = False)]\n",
    "tweets = df4.tolist()\n",
    "\n",
    "#Find Common correlated Bigrams, for name search, 5 grams for \"name and name\"\n",
    "words = []\n",
    "bigrams = []\n",
    "pentgrams = []\n",
    "for tweet in tweets:\n",
    " #   tweet = tweet.lower()\n",
    "    clean_string = re.sub('[^A-Za-z0-9]+', ' ', tweet)\n",
    "    tokens = nltk.word_tokenize(clean_string)\n",
    "    grams1 = ngrams(tokens, 1)\n",
    "    grams2 = ngrams(tokens, 2)\n",
    "    grams5 = ngrams(tokens, 5)\n",
    "    for gram in grams1:\n",
    "        words.append(gram)\n",
    "    for gram in grams2:\n",
    "        bigrams.append(gram)\n",
    "    for gram in grams5:\n",
    "        pentgrams.append(gram)\n",
    "    common1 = Counter(words).most_common()\n",
    "    common2 = Counter(bigrams).most_common()\n",
    "    common5 = Counter(pentgrams).most_common()\n",
    "names = nltk.corpus.names.words()\n",
    "\n",
    "def accumulate_votes(words, bigrams, pentgrams):\n",
    "    hosts = {}\n",
    "    for word in words:\n",
    "        untokenize = ' '.join(word[0])\n",
    "        hosts[untokenize] = word[1] \n",
    "    for gram in bigrams:\n",
    "        untokenize = ' '.join(gram[0])\n",
    "        votes = gram[1]\n",
    "        if gram[0][0] in hosts:\n",
    "            if gram[0][0] in names:\n",
    "                votes *= 2\n",
    "            votes += hosts[gram[0][0]]\n",
    "        if gram[0][1] in hosts:\n",
    "            if gram[0][1] in names:\n",
    "                votes *= 2\n",
    "            votes += hosts[gram[0][1]]\n",
    "        if gram[0][1][0].isupper() and gram[0][0][0].isupper():\n",
    "            votes *= 2\n",
    "        hosts[untokenize] = votes\n",
    "    for gram in pentgrams:\n",
    "        if gram[0][0] == \"Hosts\":\n",
    "            host1 = gram[0][1] + \" \" + gram[0][2]\n",
    "            if host1 in hosts:\n",
    "                hosts[host1] = hosts[host1] * 2\n",
    "            host2 = gram[0][3] + \" \" + gram[0][4]\n",
    "            if host2 in hosts:\n",
    "                hosts[host2] = hosts[host2] * 2\n",
    "        if gram[0][2] == \"and\":\n",
    "            host1 = gram[0][0] + \" \" + gram[0][1]\n",
    "            if host1 in hosts:\n",
    "                hosts[host1] = hosts[host1] * 2\n",
    "            host2 = gram[0][3] + \" \" + gram[0][4]\n",
    "            if host2 in hosts:\n",
    "                hosts[host2] = hosts[host2] * 2\n",
    "    return sorted(hosts.items(), key = lambda x: x[1], reverse = True)\n",
    "\n",
    "host = accumulate_votes(common1, common2, common5)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import string\n",
    "\n",
    "#st = StanfordNERTagger('stanford-ner/classifiers/english.all.3class.distsim.crf.ser.gz','stanford-ner/stanford-ner.jar')\n",
    "punc = string.punctuation\n",
    "names = nltk.corpus.names.words()\n",
    "\n",
    "results = {}\n",
    "rexp = '[A-Z][a-z]* [A-Z][a-z]*'\n",
    "for awards_name,awards_tweets in store.items():\n",
    "    temp_result = {}\n",
    "    result = []\n",
    "    flag = 0\n",
    "    if any(occupation in awards_name for occupation in occupation_words):\n",
    "        for awards_tweet in awards_tweets:\n",
    "            x = re.findall(rexp,awards_tweet)\n",
    "            if len(x)!= 0:\n",
    "                for sx in x:\n",
    "                    #print(sx)\n",
    "                    tokens = nltk.word_tokenize(sx)\n",
    "                    #print(tokens)\n",
    "                    if tokens[0] in names:\n",
    "                        #print(dataframe[extraid])\n",
    "                        result.append(sx)\n",
    "    else:\n",
    "        result = store[awards_name]\n",
    "    temp_result = (Counter(result).most_common())\n",
    "    if len(temp_result)> 1 and temp_result[0][1] > 50:\n",
    "        for pre_name, pre_result in results.items():\n",
    "            if temp_result[0][0] == pre_result[0][0] and temp_result[1][0] == pre_result[1][0]:\n",
    "                #print(temp_result)\n",
    "                #print(results[pre_name])\n",
    "                if temp_result[0][1] > pre_result[0][1]:\n",
    "                    results[pre_name] = temp_result\n",
    "                    flag = 1\n",
    "    \n",
    "        if flag == 0:\n",
    "            results[awards_name] = temp_result\n",
    "\n",
    "    #print(result)\n",
    "#pprint(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best director - motion picture\n",
      "best actor - motion picture drama\n",
      "best actress - motion picture drama\n",
      "best actress - motion picture comedy / musical\n",
      "best actress - tv series drama\n",
      "best actor comedy / musical\n",
      "best motion picture drama\n",
      "best motion picture comedy / musical\n",
      "best actress - comedy\n",
      "best actor tv series drama\n",
      "best original song - motion picture\n",
      "best screenplay award\n",
      "best supporting actress - tv movie series / miniseries\n",
      "best tv series drama\n",
      "best actress - miniseries / tv movie\n",
      "best actor - tv comedy\n",
      "best actor - miniseries / tv movie\n",
      "best supporting actress - motion picture\n",
      "best actor - mini-series / tv movie\n",
      "best supporting actor - series mini-series / tv movie\n",
      "best actress - motion picture\n",
      "best actor - series\n",
      "best screenplay\n",
      "best screenplay golden globe\n"
     ]
    }
   ],
   "source": [
    "for award in store.keys():\n",
    "    if award in results.keys():\n",
    "        #print(award[0],results[award[0]])\n",
    "        print(award)\n",
    "    #else:\n",
    "     #   del tweet_store[award]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_presenters(awards_store,dataframe):\n",
    "    presenter_store = {}\n",
    "    scope = 20\n",
    "    names = nltk.corpus.names.words()\n",
    "    rexp = '[A-Z][a-z]* [A-Z][a-z]*'\n",
    "    for award_name, tweets in awards_store.items():\n",
    "        present_list = []\n",
    "        for tid, tweet in tweets:\n",
    "            if scope < tid < len(dataframe)-scope:\n",
    "                for extraid in range(tid-scope,tid+scope):\n",
    "                    if 'present' in dataframe[extraid].lower() or 'introduc' in dataframe[extraid].lower():\n",
    "                        x = re.findall(rexp,dataframe[extraid])\n",
    "                        if len(x)!= 0:\n",
    "                            for sx in x:\n",
    "                                #print(sx)\n",
    "                                tokens = nltk.word_tokenize(sx)\n",
    "                                #print(tokens)\n",
    "                                if tokens[0] in names:\n",
    "                                    #print(dataframe[extraid])\n",
    "                                    present_list.append(sx)\n",
    "        presenter_store[award_name] = Counter(present_list).most_common()[:3]\n",
    "    return presenter_store\n",
    "\n",
    "present_store = find_presenters(tweet_store,df)\n",
    "#pprint(present_store)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_related_nominees(awards_store,dataframe):\n",
    "    nominees_store = {}\n",
    "    scope = 20\n",
    "    names = nltk.corpus.names.words()\n",
    "    rexp = '[A-Z][a-z]* [A-Z][a-z]*'\n",
    "    for award_name, tweets in awards_store.items():\n",
    "        nominee_list = []\n",
    "        if any(occupation in award_name for occupation in occupation_words):\n",
    "            for tid, tweet in tweets:\n",
    "                if scope < tid < len(dataframe)-scope:\n",
    "                    for extraid in range(tid-scope,tid+scope):\n",
    "                        if 'win' in dataframe[extraid].lower():\n",
    "                            x = re.findall(rexp,dataframe[extraid])\n",
    "                            if len(x)!= 0:\n",
    "                                for sx in x:\n",
    "                                    #print(sx)\n",
    "                                    tokens = nltk.word_tokenize(sx)\n",
    "                                    #print(tokens)\n",
    "                                    if tokens[0] in names:\n",
    "                                        print(dataframe[extraid])\n",
    "                                        nominee_list.append(sx)\n",
    "        else:\n",
    "            if award_name in results.keys():\n",
    "                nominee_list = results[award_name][:5]\n",
    "        nominees_store[award_name] = Counter(nominee_list).most_common()[:5]\n",
    "    return nominees_store\n",
    "\n",
    "#nominees_store1 = find_related_nominees(tweet_store,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_similar(name1, name2):\n",
    "    nt1 = nltk.word_tokenize(name1)\n",
    "    nt2 = nltk.word_tokenize(name2)\n",
    "    if any(tk in nt1 for tk in nt2):\n",
    "        return True\n",
    "    if nltk.edit_distance(name1,name2) < 3:\n",
    "        return True\n",
    "    return False\n",
    "#print (is_similar('Richard Linklater','Ava Du'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_nominees(results):\n",
    "    nominees_store = {}\n",
    "    occupation_words = [\"actor\",\"director\",\"actress\",\"singer\",\"scientist\"]\n",
    "    rexp = '[A-Z][a-z]* [A-Z][a-z]*'\n",
    "    for awards_name, result in results.items():\n",
    "        nominee = []\n",
    "         # Merge People\n",
    "        if any(occupation in awards_name for occupation in occupation_words):\n",
    "            for name in result:\n",
    "                x = re.findall(rexp,name[0])\n",
    "                if len(x)!=0:\n",
    "                    if len(nominee) == 0:\n",
    "                        nominee.append(name)\n",
    "                    else:\n",
    "                        if not any(is_similar(prev_name[0],name[0]) for prev_name in nominee):\n",
    "                            nominee.append(name)\n",
    "\n",
    "        else:\n",
    "            nominee = results[awards_name][:5]\n",
    "        nominees_store[awards_name] = nominee\n",
    "    return nominees_store\n",
    "\n",
    "nominees_store2 = find_nominees(results)\n",
    "#pprint(nominees_store2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdress = df\n",
    "df2 = dfdress[dfdress.str.contains(\" dressed \", case = False)]\n",
    "\n",
    "df3 = df2[df2.str.contains(\" best \", case = False)]\n",
    "best_tweets = df3.tolist()\n",
    "df4 = df2[df2.str.contains(\" worst \", case = False)]\n",
    "worst_tweets = df4.tolist()\n",
    "df5 = df[df.str.contains(\" carpet \", case = False)]\n",
    "mentions = df5.tolist()\n",
    "\n",
    "def find_most_common_name(tweets):\n",
    "    bigrams = []\n",
    "    for tweet in tweets:\n",
    " #   tweet = tweet.lower()\n",
    "        clean_string = re.sub('[^A-Za-z0-9]+', ' ', tweet)\n",
    "        tokens = nltk.word_tokenize(clean_string)\n",
    "        grams2 = ngrams(tokens, 2)\n",
    "        for gram in grams2:\n",
    "            bigrams.append(gram)\n",
    "    common2 = Counter(bigrams).most_common()\n",
    "    names = nltk.corpus.names.words()\n",
    "    people = {}\n",
    "    for gram in common2:\n",
    "        untokenize = ' '.join(gram[0])\n",
    "        votes = gram[1]\n",
    "        if gram[0][0] in names:\n",
    "            votes *= 3\n",
    "        if gram[0][1] in names:\n",
    "            votes *= 2\n",
    "        if gram[0][1][0].isupper() and gram[0][0][0].isupper() and untokenize != \"Red Carpet\" and untokenize != \"Golden Globes\":\n",
    "            if gram[0][0] not in names and gram[0][1] not in names:\n",
    "                votes *= 1.5\n",
    "            elif gram[0][0] in names and gram[0][1] in names:\n",
    "                votes *= 4\n",
    "            elif gram[0][0] in names or gram[0][1] in names:\n",
    "                votes *= 3\n",
    "            else:\n",
    "                votes *= 2\n",
    "        people[untokenize] = votes\n",
    "    return sorted(people.items(), key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Mentioned on Red Carpet: Kerry Washington\n",
      "Best Dressed on Red Carpet: Tina Fey\n",
      "Worst Dressed on Red Carpet: See The\n"
     ]
    }
   ],
   "source": [
    "most_mentioned = find_most_common_name(mentions)\n",
    "best_dressed = find_most_common_name(best_tweets)\n",
    "worst_dressed = find_most_common_name(worst_tweets)\n",
    "print(\"Most Mentioned on Red Carpet:\", most_mentioned[0][0])\n",
    "print(\"Best Dressed on Red Carpet:\", best_dressed[0][0])\n",
    "print(\"Worst Dressed on Red Carpet:\", worst_dressed[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_name(item_list):\n",
    "    rexp = '[A-Z][a-z]* [A-Z][a-z]*'\n",
    "    names = nltk.corpus.names.words()\n",
    "    result = []\n",
    "    for item in item_list:\n",
    "        x = re.findall(rexp,item[0])\n",
    "        if len(x)!= 0:\n",
    "            for sx in x:                         \n",
    "                tokens = nltk.word_tokenize(sx)                         \n",
    "                if tokens[0] in names and tokens[1] in names:\n",
    "                    result = item\n",
    "                    return result\n",
    "\n",
    "most_mentioned1 = output_name(most_mentioned)\n",
    "best_dressed1 = output_name(best_dressed)\n",
    "worst_dressed1 = output_name(worst_dressed)\n",
    "#worst_dressed1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "def get_sentiment(tweets):\n",
    "    neu = 0\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for tweet in tweets:\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        ss = sid.polarity_scores(tweet)\n",
    "        neu += ss['neu']\n",
    "        pos += ss['pos']\n",
    "        neg += ss['neg']\n",
    "    sentiment = {}\n",
    "    sentiment['Neutral'] = neu / len(tweets)\n",
    "    sentiment['Positive'] = pos / len(tweets)\n",
    "    sentiment['Negative'] = neg / len(tweets)\n",
    "    return sentiment\n",
    "\n",
    "def analyze_sentiment(dataset,words_string):\n",
    "\n",
    "    #Example for sentiment towards Tina Fey\n",
    "    df2 = dataset[dataset.str.contains(words_string, case = False)]\n",
    "    if len(df2)>100:\n",
    "        tweets = df2.iloc[0:100].tolist()\n",
    "    else:\n",
    "        tweets = df2.tolist()\n",
    "    senti = get_sentiment(tweets)\n",
    "    print(senti)\n",
    "    return senti\n",
    "\n",
    "\n",
    "#analyze_sentiment(df,\"Tina\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host: \n",
      "Tina Fey\n",
      "Amy Poehler\n",
      "\n",
      "\n",
      "Most Mentioned on Red Carpet: Kerry Washington\n",
      "Best Dressed on Red Carpet: Tina Fey\n",
      "Worst Dressed on Red Carpet: Lana Del\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Director - Motion Picture\n",
      "Presenter: \n",
      "('Harrison Ford', 35)\n",
      "Nominess: \n",
      "[('Richard Linklater', 404), ('Ava Du', 47), ('Wes Anderson', 1), ('David Fincher', 1), ('Alejandro Gonz', 1)]\n",
      "Winner: \n",
      "('Richard Linklater', 404)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.8304600000000008, 'Positive': 0.16565000000000005, 'Negative': 0.0038900000000000002}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Actor - Motion Picture Drama\n",
      "Presenter: \n",
      "('Gwyneth Paltrow', 26)\n",
      "Nominess: \n",
      "[('Eddie Redmanye', 222), ('David Oyelowo', 11), ('Jake Gyllenhaal', 6), ('Benedict Cumberbatch', 5), ('Steve Carell', 2)]\n",
      "Winner: \n",
      "('Eddie Redmanye', 222)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.76865, 'Positive': 0.23135000000000036, 'Negative': 0.0}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Actress - Motion Picture Drama\n",
      "Presenter: \n",
      "('Jamie Dornan', 19)\n",
      "Nominess: \n",
      "[('Julianne Moore', 398), ('Jennifer Aniston', 9), ('Patricia Arquette', 9), ('Rosamund Pike', 8), ('Felicity Jones', 5)]\n",
      "Winner: \n",
      "('Julianne Moore', 398)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.8387900000000004, 'Positive': 0.1251099999999999, 'Negative': 0.03609}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Actress - Motion Picture Comedy / Musical\n",
      "Presenter: \n",
      "('Ricky Gervais', 77)\n",
      "Nominess: \n",
      "[('Amy Adams', 460), ('Marilyn Monroe', 14), ('Helen Mirren', 5), ('Julianne Moore', 4), ('Emily Blunt', 4)]\n",
      "Winner: \n",
      "('Amy Adams', 460)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.7875899999999997, 'Positive': 0.19375000000000003, 'Negative': 0.01866}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Actress - Tv Series Drama\n",
      "Presenter: \n",
      "('Chris Pratt', 54)\n",
      "Nominess: \n",
      "[('Ruth Wilson', 429), ('Tatiana Maslany', 4), ('Chris Pratt', 3), ('Viola Davis', 3), ('Julianna Marguiles', 2)]\n",
      "Winner: \n",
      "('Ruth Wilson', 429)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.7812499999999999, 'Positive': 0.13137000000000001, 'Negative': 0.08735}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Actor Comedy / Musical\n",
      "Presenter: \n",
      "('Kristen Wiig', 53)\n",
      "Nominess: \n",
      "[('Jeffrey Tambor', 375), ('Michael Keaton', 11), ('Bill Murray', 6), ('Ralph Fiennes', 4), ('Emily Blunt', 4)]\n",
      "Winner: \n",
      "('Jeffrey Tambor', 375)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.7165600000000001, 'Positive': 0.2536899999999999, 'Negative': 0.02974}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Motion Picture Drama\n",
      "Presenter: \n",
      "('Tina Fey', 448)\n",
      "Nominess: \n",
      "[('\"Boyhood\"', 285), ('\"Selma\"', 5), ('\"The Grand Budapest Hotel\"', 4), ('\"Best Drama Motion Picture\"', 2), ('\"Theory Of Everything\"', 1)]\n",
      "Winner: \n",
      "('\"Boyhood\"', 285)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.8185999999999994, 'Positive': 0.1765100000000005, 'Negative': 0.00489}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Motion Picture Comedy / Musical\n",
      "Presenter: \n",
      "('Robert Downey', 1017)\n",
      "Nominess: \n",
      "[('\"The Grand Budapest Hotel\"', 136), ('\"Grand Budapest Hotel\"', 5)]\n",
      "Winner: \n",
      "('\"The Grand Budapest Hotel\"', 136)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.5413600000000003, 'Positive': 0.42213000000000006, 'Negative': 0.03650999999999998}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Actress - Comedy\n",
      "Presenter: \n",
      "('Kate Beckinsale', 25)\n",
      "Nominess: \n",
      "[('Gina Rodriguez', 458), ('Jane The', 255), ('Tony Smith', 1), ('Amy Adams', 1), ('Kerry Washington', 1)]\n",
      "Winner: \n",
      "('Gina Rodriguez', 458)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.7969499999999996, 'Positive': 0.19201000000000004, 'Negative': 0.01104}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Actor Tv Series Drama\n",
      "Presenter: \n",
      "('Katherine Heigl', 61)\n",
      "Nominess: \n",
      "[('Kevin Spacey', 431), ('Clive Owen', 4), ('James Spader', 4), ('Dominic West', 4), ('Frank Underwood', 3)]\n",
      "Winner: \n",
      "('Kevin Spacey', 431)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.8545999999999999, 'Positive': 0.08818000000000001, 'Negative': 0.057229999999999996}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Original Song - Motion Picture\n",
      "Presenter: \n",
      "('John Legend', 113)\n",
      "Nominess: \n",
      "[('\"Glory\"', 308), ('\"Selma\"', 69), ('\"Prediction\"', 1)]\n",
      "Winner: \n",
      "('\"Glory\"', 308)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.64007, 'Positive': 0.35770000000000024, 'Negative': 0.0022400000000000002}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Screenplay Award\n",
      "Presenter: \n",
      "('Kristen Wiig', 103)\n",
      "Nominess: \n",
      "[('\"Birdman\"', 57), ('\"Gone Girl\"', 6)]\n",
      "Winner: \n",
      "('\"Birdman\"', 57)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.87702, 'Positive': 0.11112999999999999, 'Negative': 0.011850000000000001}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Supporting Actress - Tv Movie Series / Miniseries\n",
      "Presenter: \n",
      "('Benedict Cumberbatch', 49)\n",
      "Nominess: \n",
      "[('Joanne Froggatt', 458)]\n",
      "Winner: \n",
      "('Joanne Froggatt', 458)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.6716600000000006, 'Positive': 0.32834000000000046, 'Negative': 0.0}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Tv Series Drama\n",
      "Presenter: \n",
      "('Paul Rudd', 56)\n",
      "Nominess: \n",
      "[('\"The Affair\"', 103), ('\"The Good Wife\"', 1), ('\"X\"', 1)]\n",
      "Winner: \n",
      "('\"The Affair\"', 103)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.6995899999999999, 'Positive': 0.28191999999999995, 'Negative': 0.018490000000000003}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Actress - Miniseries / Tv Movie\n",
      "Presenter: \n",
      "('Benedict Cumberbatch', 51)\n",
      "Nominess: \n",
      "[('Joanne Froggatt', 455)]\n",
      "Winner: \n",
      "('Joanne Froggatt', 455)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.6716600000000006, 'Positive': 0.32834000000000046, 'Negative': 0.0}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Actor - Tv Comedy\n",
      "Presenter: \n",
      "('Kristen Wiig', 65)\n",
      "Nominess: \n",
      "[('Jeffrey Tambor', 433), ('Don Cheadle', 5), ('Louis C', 4), ('William H', 3), ('Ricky Gervais', 2)]\n",
      "Winner: \n",
      "('Jeffrey Tambor', 433)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.7165600000000001, 'Positive': 0.2536899999999999, 'Negative': 0.02974}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Actor - Miniseries / Tv Movie\n",
      "Presenter: \n",
      "('Jeremy Renner', 15)\n",
      "Nominess: \n",
      "[('Billy Bob', 487), ('Martin Freeman', 1), ('Jeremy Renner', 1), ('Thornton I', 1)]\n",
      "Winner: \n",
      "('Billy Bob', 487)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.77338, 'Positive': 0.17673999999999995, 'Negative': 0.0499}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Supporting Actress - Motion Picture\n",
      "Presenter: \n",
      "('Jared Leto', 34)\n",
      "Nominess: \n",
      "[('Patricia Arquette', 434), ('Joanne Froggatt', 16), ('Jared Leto', 3), ('Emma Stone', 2), ('Jessica Chastain', 2)]\n",
      "Winner: \n",
      "('Patricia Arquette', 434)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.8491499999999997, 'Positive': 0.13188999999999995, 'Negative': 0.018960000000000005}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Actor - Mini-series / Tv Movie\n",
      "Presenter: \n",
      "('Gina Rodriguez', 16)\n",
      "Nominess: \n",
      "[('Billy Bob', 382), ('Matt Bomer', 91), ('Thornton Wins', 12), ('Matthew Mc', 2), ('Jeremy Renner', 1)]\n",
      "Winner: \n",
      "('Billy Bob', 382)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.77338, 'Positive': 0.17673999999999995, 'Negative': 0.0499}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Supporting Actor - Series Mini-series / Tv Movie\n",
      "Presenter: \n",
      "('Katie Holmes', 34)\n",
      "Nominess: \n",
      "[('Matt Bomer', 406), ('Bill Murray', 1), ('Angelina Jolie', 1), ('Mark Ruffalo', 1)]\n",
      "Winner: \n",
      "('Matt Bomer', 406)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.8582400000000001, 'Positive': 0.11691999999999993, 'Negative': 0.024849999999999997}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Actress - Motion Picture\n",
      "Presenter: \n",
      "('Ricky Gervais', 75)\n",
      "Nominess: \n",
      "[('Amy Adams', 368), ('Joanne Froggatt', 16), ('Marilyn Monroe', 14), ('Jennifer Aniston', 6), ('Julianne Moore', 5)]\n",
      "Winner: \n",
      "('Amy Adams', 368)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.7875899999999997, 'Positive': 0.19375000000000003, 'Negative': 0.01866}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Actor - Series\n",
      "Presenter: \n",
      "('Jeremy Renner', 23)\n",
      "Nominess: \n",
      "[('Billy Bob', 423), ('James Spader', 9), ('Jamie Dorman', 7), ('Kevin Spacey', 5), ('Mark Ruffalo', 3)]\n",
      "Winner: \n",
      "('Billy Bob', 423)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.77338, 'Positive': 0.17673999999999995, 'Negative': 0.0499}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Screenplay\n",
      "Presenter: \n",
      "('Kristen Wiig', 1023)\n",
      "Nominess: \n",
      "[('\"Birdman\"', 132), ('\"Good Will Hunting\"', 26), ('\"Gone Girl\"', 6), ('\"Best Screenplay\"', 4), ('\"The Imitation Game\"', 3)]\n",
      "Winner: \n",
      "('\"Birdman\"', 132)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.87702, 'Positive': 0.11112999999999999, 'Negative': 0.011850000000000001}\n",
      "\n",
      "\n",
      "Award Name: \n",
      "Best Screenplay Golden Globe\n",
      "Presenter: \n",
      "('Kristen Wiig', 980)\n",
      "Nominess: \n",
      "[('\"Birdman\"', 132), ('\"Good Will Hunting\"', 26), ('\"Gone Girl\"', 6), ('\"Best Screenplay\"', 4), ('\"On Your Feet\"', 3)]\n",
      "Winner: \n",
      "('\"Birdman\"', 132)\n",
      "Attitude to Winner: \n",
      "{'Neutral': 0.87702, 'Positive': 0.11112999999999999, 'Negative': 0.011850000000000001}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1 = open('human_readable_results.txt','w')\n",
    "write_string = \"\"\n",
    "\n",
    "print(\"Host: \")\n",
    "write_string += \"Host: \"\n",
    "print(host[0][0])\n",
    "write_string += host[0][0]\n",
    "write_string +=\", \"\n",
    "print(host[1][0])\n",
    "write_string += host[1][0]\n",
    "print(\"\\n\")\n",
    "write_string += \"\\n\"\n",
    "\n",
    "print(\"Most Mentioned on Red Carpet:\", most_mentioned1[0])\n",
    "write_string += (\"Most Mentioned on Red Carpet: \"+ most_mentioned1[0]+'\\n')\n",
    "print(\"Best Dressed on Red Carpet:\", best_dressed1[0])\n",
    "write_string += (\"Best Dressed on Red Carpet: \"+ best_dressed1[0]+'\\n')\n",
    "print(\"Worst Dressed on Red Carpet:\", worst_dressed1[0])\n",
    "write_string += (\"Worst Dressed on Red Carpet: \"+ worst_dressed1[0]+'\\n')\n",
    "print(\"\\n\")\n",
    "write_string += \"\\n\"\n",
    "\n",
    "for award_name, award_result in results.items():\n",
    "    c_award_name = []\n",
    "    nt = nltk.word_tokenize(award_name)\n",
    "    for token in nt:\n",
    "        ct = token.capitalize()\n",
    "        c_award_name.append(ct)\n",
    "    c_name = ' '.join(c_award_name)\n",
    "    nomlist = []\n",
    "    for i in range(len(nominees_store2[award_name][:5])):\n",
    "        nomlist.append(nominees_store2[award_name][i][0])\n",
    "\n",
    "    write_string += \"Award Name: \"\n",
    "    print(\"Award Name: \")\n",
    "    print(c_name)\n",
    "    write_string += c_name\n",
    "    write_string += \"\\n\"\n",
    "\n",
    "\n",
    "    write_string += \"Presenter: \"\n",
    "    print(\"Presenter: \")\n",
    "    print(present_store[award_name][0])\n",
    "    write_string += present_store[award_name][0][0]\n",
    "    write_string += \"\\n\"\n",
    "\n",
    "    write_string += \"Nominess: \"\n",
    "    print(\"Nominess: \")\n",
    "    #print(nominees_store1[award_name])\n",
    "    print(nominees_store2[award_name][:5])\n",
    "    write_string += str(nomlist)\n",
    "    write_string += \"\\n\"\n",
    "\n",
    "    write_string += \"Winner: \"\n",
    "    print(\"Winner: \")\n",
    "    print(award_result[0])\n",
    "    write_string += award_result[0][0]\n",
    "    write_string += \"\\n\"\n",
    "\n",
    "    write_string += \"Attitude to Winner: \"\n",
    "    print(\"Attitude to Winner: \")\n",
    "    astr = analyze_sentiment(df,award_result[0][0])\n",
    "    print(\"\\n\")\n",
    "    write_string += str(astr)\n",
    "    write_string += \"\\n\"\n",
    "    write_string += \"\\n\"\n",
    "\n",
    "f1.write(write_string)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "final_data = {\"Host\":[host[0][0],host[1][0]]}\n",
    "\n",
    "\n",
    "\n",
    "for award_name in results.keys():\n",
    "    c_award_name = []\n",
    "    nt = nltk.word_tokenize(award_name)\n",
    "    for token in nt:\n",
    "        ct = token.capitalize()\n",
    "        c_award_name.append(ct)\n",
    "    c_name = ' '.join(c_award_name)\n",
    "    nomlist = []\n",
    "    for i in range(len(nominees_store2[award_name][:5])):\n",
    "        nomlist.append(nominees_store2[award_name][i][0])\n",
    "    final_data.update({\n",
    "        c_name:{\n",
    "            \"Presenter:\":present_store[award_name][0][0],\n",
    "            \"Nominees:\":nomlist,\n",
    "            \"Winner:\":results[award_name][0][0]\n",
    "        }\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open('result.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(final_data, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f40074d2c94983a8faedb89fc439bf088f1a6d4f0a1d77ecd1da0a25da451a1f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('NLP_Mining': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
