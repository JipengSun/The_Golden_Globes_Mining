{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a20ece5-2a04-42c2-86f4-b3a6129fc6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('!', '!'), ('!', '!')),\n",
       " (('best', 'original'), ('original', 'song')),\n",
       " (('the', 'golden'), ('golden', 'globes')),\n",
       " (('at', 'the'), ('the', 'golden')),\n",
       " (('best', 'director'), ('director', '.')),\n",
       " (('best', 'supporting'), ('supporting', 'actress')),\n",
       " (('best', 'director'), ('director', 'at')),\n",
       " (('director', 'at'), ('at', 'the')),\n",
       " (('director', '.'), ('best', 'director')),\n",
       " (('golden', 'globes'), ('globes', '.')),\n",
       " (('original', 'song'), ('song', 'for')),\n",
       " (('the', '#'), ('#', 'goldenglobes')),\n",
       " (('best', 'director'), ('director', 'for')),\n",
       " (('best', 'motion'), ('motion', 'picture')),\n",
       " (('actor', 'in'), ('in', 'a')),\n",
       " (('actress', 'in'), ('in', 'a')),\n",
       " (('best', 'supporting'), ('supporting', 'actor')),\n",
       " ((',', 'drama'), ('drama', '...')),\n",
       " (('a', 'motion'), ('motion', 'picture')),\n",
       " (('actress', ','), (',', 'drama')),\n",
       " (('best', 'actor'), ('actor', 'in')),\n",
       " (('best', 'actress'), ('actress', ',')),\n",
       " (('#', 'goldenglobes'), ('best', 'original')),\n",
       " (('at', 'the'), ('the', '#')),\n",
       " (('globes', '.'), ('best', 'director')),\n",
       " (('in', 'a'), ('a', 'motion')),\n",
       " ((\"'\", 'http'), ('http', ':')),\n",
       " ((\"'ben\", \"'\"), (\"'\", 'http')),\n",
       " (('best', 'actress'), ('actress', 'for')),\n",
       " (('best', 'picture'), ('picture', '!'))]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "quadgram_measures = nltk.collocations.QuadgramAssocMeasures()\n",
    "\n",
    "#Strategy 1 scan after the word won:\n",
    "df = pd.read_json(\"gg2013.json/gg2013.json\")\n",
    "df2 = df[df['text'].str.contains(\" won \") | df['text'].str.contains(\" Won \")]\n",
    "tweets = df2['text'].tolist()\n",
    "keywords = []\n",
    "regexp = re.compile(r'[!?.]+(?=$|\\s)')\n",
    "\n",
    "#Parse Keywords\n",
    "for tweet in tweets:\n",
    "    words = tweet.lower().split()\n",
    "    index_won = words.index(\"won\")\n",
    "    if words[index_won + 1] == \"best\":\n",
    "        keyword = \"best \"\n",
    "        curr_index = index_won + 2\n",
    "        while curr_index != len(words):\n",
    "            if regexp.search(words[curr_index]):\n",
    "                keyword += words[curr_index]\n",
    "                break\n",
    "            keyword += words[curr_index] + \" \"\n",
    "            curr_index += 1\n",
    "        keywords.append(keyword)\n",
    "\n",
    "#Analyze common phrase occurences\n",
    "bigrams = []\n",
    "for item in keywords:\n",
    "    tokens = nltk.word_tokenize(item)\n",
    "    grams = ngrams(tokens, 2)\n",
    "    for gram in grams:\n",
    "        bigrams.append(gram)\n",
    "finder = BigramCollocationFinder.from_words(bigrams)\n",
    "finder.apply_freq_filter(3)\n",
    "#ignored_words = nltk.corpus.stopwords.words('english')\n",
    "#finder.apply_word_filter(lambda w: len(w) < 3 or w.lower() in ignored_words)\n",
    "finder.nbest(bigram_measures.raw_freq, 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
